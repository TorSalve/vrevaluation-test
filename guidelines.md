---
layout: page
title: Guidelines
navigation: 2
nav_order: 2
---

# VR object selection and manipulation study guidelines

[Contribute via Google Docs](https://github.com/TorSalve/vrevaluation-test/)

### 1. Define the goal of the evaluation
{:toc}

We recommend deciding early on whether the goal of the study is toevaluate speed or accuracy in object selection or manipulation. The main dependent variable should clearlyfollow from this. The purpose of this recommendation is to either eliminate errors from analysing speed (as inthe Fitts’ paradigms), or to focus on analysing accuracy. The pitfalls of combining speed and accuracy in thestudy design include, for instance, to restrict completion time and judge errors from exceeded time when thegoal is to measure accuracy. If the goal is to investigate speed (i.e., task completion time) in selection tasks, we recommend using the sizedifference between the cursor and the target object as the error threshold. It should also be required that the firstis completely inside the second for successful task completion. If the cursor is a single-pixel cursor, the targetsize gives the error threshold (as the width does in ISO task). If the task is a manipulation task, we recommendusing thresholds for object placement (e.g., the thresholds for aligning cubes can be expressed as X mm and Ydegrees, as in Yang et al. [88]). That way, the speed can be analysed from (successful) completion times eitherafter a selection or after the threshold of manipulation is met. If the goal is to measure accuracy, we recommend a free range for possible end-positions, confirmed withsome selection trigger. Here, all selections are accepted, and the distance (whether of a single-pixel cursor froma single-pixel crosshair target [50], or the angular difference along the three axes of rotation from the targetobject’s rotation [48]) is measured and analysed as a continuous accuracy variable. Finally, while speed and accuracy should not be combined in the goals, we recommend doing so in analysiswhen it is possible and useful for insights. This can be done by analysing throughput with effective IDs [71]; note,however, the concerns that for instance Stuerlinger and Teather [74] presented for doing this with non-sphericalhit distributions in 3D.

### 2. Estimate the required number of participants with power analysis
{:toc}

The average number of participantsper study in our sample was 18. 8, whereas in general in HCI, it is 20–30 [5,15]. We should strive to reach at leastthat range. We also recommend reporting effect sizes with statistical tests as this helps others to conduct a prioripower analyses to better estimate the required sample size. If estimation is not possible, we recommend using aminimum of 20 participants. We also recommend the inclusion of expert participants, as VR has strong noveltyeffects, especially on subjective measures. Including expert participants can reduce this bias and move towardsassessments of VR as a mainstream technology. To measure expertise, we recommend using objective scales,such as options with how often related technology is used (e.g., daily, or N times a week as in Sidenmark andGellersen [69]) rather than reflective ones without a baseline (e.g., "rate your expertise from 1 to 5" [72]).

### 3. Strive for high control with a simple study design
{:toc}

We recommend using a maximum of three independentvariables or factors. Nearly all studies (92. 7%) used a within-subject design, which we also recommend usingto decrease the influence of interpersonal variability on the performance in these low-level tasks. However,counterbalancing the order of study conditions in a within-subject design becomes tricky when there are manyconditions (again, a simple design helps) but it’s widely accepted that counterbalancing is usually necessary todecrease learning effects. Clearly define the independent variables and their levels in the study. When there is more than one independentvariable or group, we recommend reporting them and their levels in the N&times;M&times;P format. It is essential toinclude all the factors varied. We noticed that when following this style only partially (e.g., "for each interactiontechnique, there were 24 conditions (2&times;2&times;3&times;2)" [85], there are actually two techniques, giving 48 conditionsin total), the study designs are hard to follow, and the analysis methods remain unclear. However, if a study design results in many conditions, two approaches may help simplify the design. First,consider combining target distances and sizes into different IDs: you can include targets at different depths, forinstance, by increasing the target size or decreasing the distance so that it matches the IDs (see an example inTu et al. [78]). Second, consider decreasingdevice&times;techniquecombinations by fixing either as a constant. Forexample, control the device type as an independent variable when your study is about a technique and vice versa.

### 4. Use low-level tasks in evaluations
{:toc}

When the goal of a study is to compare interaction techniques, werecommend using low-level tasks: pointing and selection, or translation and rotation. Such tasks help to generalisethe benefits of interaction techniques to any higher-level tasks: the performance in those is always dependenton the lower-level components (as LaViola et al. also suggest [38]). Additionally, using lower-level tasks helpsisolate and gain insights into the tested techniques’ particular strengths and weaknesses. For selection techniques, the lower-level tasks are pointing and selection. We recommend separating these inthe study design. To do this, the study design can fix the alternate low-level task as a constant. For example,selection can be made via a button press when studying pointing techniques, or by using a single pointingtechnique (e.g., ray-casting as in [6]) when studying the effects of a selection method on accuracy. If theselow-level tasks are combined, we recommend designing dependent measures such that the performance in thetwo sub-tasks can be separated. Treating both as independent variables is often unnecessary and results in acomplex study design (recommendation (1)). For manipulation tasks, we recommend including at least translation and rotation tasks. We recommendperforming the tasks including translation with a target object collocated in space. This target object can bea docking point (e.g., Lee et al. [39]), or a transparent version of the object in which it needs to be co-located(e.g.,Yang et al. [88]). If the task includes rotation, the methods used for translation apply, with suitable thresholds for accurateplacement or successful co-location. Alternatively, rotation-only tasks can use a dislocated duplicate modelobject as a target (e.g., a house [79]). This is particularly useful when accuracy instead of error is measured(not to convey assumptions of successful orientation with visual co-location). In general, we recommend thefirst approach with co-located targets, to prevent other factors such as size or depth perception influencingperformance in the translation or rotation task.

### 5. Control the target distance in trials
{:toc}

Object selection and manipulation tasks can be discrete or serial. Discretetasks have a particular starting position for the task. In contrast, a serial task consists of a sequence of targets withthe starting position for the next target being the previous target (see, e.g., the two schemes for implementingthe Fitts paradigm in Soukoreff and MacKenzie[71]). We recommend using discrete tasks, as they are simpler toimplement. For example, the task can always be started at the same point in space and in relation to the targetarrangement. Therefore, it is also easy to systematically count for variation in the resulting distances of targets,movement directions toward them, etc. A serial task is more complex to implement if a circular layout (as in the ISO tapping task) is not used. This isbecause systematic target distance and size variation, as well as possible distractor targets on the optimal motionpath, need to be carefully designed and controlled. Most studies that did not use the ISO task used a discrete task. Those that did use a serial task outside of ISO, randomised the target layout instead of using a systematic controlof distance—and then failed to report the target distances resulting from randomisation. The recommendation ofa discrete task and starting position holds for selection and translation and for rotation (that is, always startingfrom the same object orientation).

### 6. Control the target size
{:toc}

We recommend using spherical targets to enable clear size control using the sphere’sdiameter (such as for width in Fitts’ law studies). This means there is no need to orient targets in the selectiontask according to the movement direction. We also recommend using either a single-pixel pointer or a fixed-sizedcursor across all tasks in a selection study. If a cursor is used, it’s size should be reported to allow correctcalculation of errors (the method for determining errors should also be reported). We recommend defining errorsas selections when the pointer is not completely inside the target object. With manipulation tasks, we recommend using color-coded cuboids or other polyhedrons that express theorientation unambiguously (e.g., tetrahedrons as in Wang and Lindeman [81]). We also recommend using thesame object shape both in the manipulated and target object (e.g., both cubes instead of placing a sphere ina cube [43]). This helps to determine the required accuracy for a successful performance (e.g., if a successfultranslation or rotation is determined by docking an object of sizedinside an object sized 1.5d [47]).

### 7. Aim for a wide and representative range of target sizes and distances
{:toc}

Soukoreff and McKenzie recom-mend using a wide and representative range of ID values for pointing device evaluation [71]. They suggestedusing ID values ranging from 2 to 8 bits. We recommend taking that as a guideline, but extending the generalrecommendation of a wide and representative range to target sizes and distances in general, and in both objectselection and manipulation. We recommend using at least 6 levels of IDs (or at least 3 distances and 3 sizes). Thestudies with ISO tasks in our survey that used 6 to 9 levels of IDs, most commonly using three sizes and threedistances. However, as mentioned above, the studies using ISO tapping tasks did not arrange targets across allthree dimensions. None of the studies with "true" 3D target arrangement in the sample included 3&times;3 levels in their design. Theyeither did not report distances (and had random targets), or varied those only at a maximum of three levels butdid not vary the size. Therefore we maintain our recommendation at a modest minimum of three levels but withan ambition t include that for both distance and size variables. We recommend using euclidian distances for selection and translation tasks, and degrees for rotation tasks. We also recommend reporting these in SI units (such as meters) and angles in degrees or radians, and in bothwhere possible (e.g., sizes and distances also as angular degrees of the visual field, such as in Tu et al. [78]).

### 8. Include a range of movement directions
{:toc}

We recommend placing targets across all three dimensions. Thevalue of a selection or manipulation technique is hard to generalise from fixed, two-dimensional planes, becauseimmersive virtual environments inherently are three-dimensional spaces, and therefore the objects of interestare likely located across the three dimensions. The performance in object selection and manipulation also variesacross different directional motions: depth control is more difficult than lateral axis control (such as on a verticalplane). For example, performance in tapping two targets at different depths in front of the user is worse thantapping two targets with the same width and at the same distance on the sides [44]. Therefore, it is important forexperimental comprehensiveness to include targets across all the three dimensions. The designs in our sample ofstudies also assimilate with the importance of this: over half (58.8%) of the studies that did not restrict themselvesinto the standard 2D ISO tapping task or involved typing on keyboards laid out targets across three dimensions.

### 9. Control the physical setting in the study
{:toc}

We recommend using a fixed standing or sitting position in thephysical space. Combining walking with object selection or manipulation adds a completely distinct task to thestudy. For example, LaViola et al. [38] and many papers about interaction techniques for VR (e.g., [9–11,30,52])treat walking as a separate task.

### 10. Control the virtual setting in the study
{:toc}

We recommend using a generic virtual environment, but with depthcues from shadows and from the surroundings, such as the ground or the walls. Depth cues are important, but realistic settings are difficult to compare with all possible distractors. Consider if your task is too specialised, if you feel a need to design a complex environment.

## References
